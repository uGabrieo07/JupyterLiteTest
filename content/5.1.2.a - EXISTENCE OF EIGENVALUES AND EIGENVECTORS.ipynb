{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number and Existence of Eigenvalues and Eigenvectors\n",
    "\n",
    "**28. Definition:** Given a linear transformation\n",
    "$\\mathbf{A}: \\mathcal{U} \\rightarrow \\mathcal{U}$ induced by a square\n",
    "matrix $\\mathbf{A}$, we say that $\\mathbf{\\nu}$ is an eigenvector of\n",
    "$\\mathbf{A}$ associated with the eigenvalue $\\lambda$ if\n",
    "$\\mathbf{\\nu} \\neq 0$ and $$\\mathbf{A \\nu} = \\lambda \\mathbf{\\nu}$$ or,\n",
    "equivalently,\n",
    "$$\\mathbf{\\nu} \\in \\mathcal{N}(\\mathbf{A} - \\lambda \\mathbf{I})$$ i.e.,\n",
    "$\\nu$ belongs to the kernel, or null space, of the transformation\n",
    "represented by $\\mathbf{A} - \\lambda \\mathbf{I}$.\n",
    "\n",
    "Although we have avoided to include vector spaces defined over the field\n",
    "of complex numbers, eigenvalues and eigenvectors will force us to\n",
    "consider eventual exceptions to this rule in the ensuing discussion.\n",
    "\n",
    "Let $\\mathbf{A}$ be a linear operator on $\\mathcal{U}$, a vector space\n",
    "defined over the field of real numbers. Now let\n",
    "$\\mathcal{U}_{\\mathbb{C}} = \\mathcal{U} \\times \\mathcal{U}$ be a vector\n",
    "space defined as\n",
    "$$\\mathcal{U}_{\\mathbb{C}} = \\{ \\nu_{\\mathbb{R}} + i \\nu_{\\mathbb{I}} : \\nu_{\\mathbb{R}}, \\nu_{\\mathbb{I}} \\in \\mathcal{U} \\}$$\n",
    "where $i = \\sqrt{-1}$. It is straightforward to show that $\\mathbf{A}$\n",
    "is a linear operator on $\\mathcal{U}_{\\mathbb{C}}$ as well.\n",
    "\n",
    "We maintain that a linear operator $\\mathbf{A}$ on $\\mathcal{U}$\n",
    "preserves some directions of $\\mathcal{U}_{\\mathbb{C}}$. If a direction\n",
    "is invariant under the transformation, then we say that a vector lying\n",
    "in this direction is an eigenvector of the transformation $A$.\n",
    "\n",
    "Before we proceed, we shall prove that\n",
    "$\\mathbf{A \\nu} = \\lambda \\mathbf{\\nu}$ is valid for a linear operator\n",
    "$\\mathbf{A}$ on $\\mathcal{U}$ and some pair\n",
    "$(\\lambda \\in \\mathbb{C}, \\nu \\in \\mathcal{U}_{\\mathbb{C}})$.\n",
    "\n",
    "Let $\\mathbf{A}$ be a linear operator on a finite-dimensional vector\n",
    "space $\\mathcal{U}$ defined over the field of real numbers. There exists\n",
    "a vector $\\nu \\in \\mathcal{U}_{\\mathbb{C}}$ and a scalar\n",
    "$\\lambda \\in \\mathbb{C}$ such that\n",
    "$\\mathbf{A\\nu} = \\lambda \\mathbf{\\nu}$.\n",
    "\n",
    "Let $n$ be the dimension of $\\mathcal{U}$. Therefore there exists a set\n",
    "of scalars $$\\alpha_0, \\alpha_1, \\dots, \\alpha_n$$, not all of them\n",
    "equal to zero, such that\n",
    "$$\\alpha_0 \\mathcal{U} + \\alpha_1 \\mathbf{A}\\mathcal{U} + \\cdots + \\alpha_n \\mathbf{A}^n \\mathcal{U} = 0$$\n",
    "for some $\\nu \\neq 0, \\nu \\in \\mathcal{U}$. This is true because we\n",
    "cannot have $n+1$ linearly independent vectors in an $n$-dimensional\n",
    "vector space. We can rewrite the equation above as\n",
    "$$0 = (\\alpha_0 + \\alpha_1 \\mathbf{A} + \\cdots + \\alpha_n \\mathbf{A}^n)\\nu = c(\\mathbf{A} - \\beta_1 I)(\\mathbf{A} - \\beta_2 I)\\cdots(\\mathbf{A} - \\beta_n I)\\nu, \\quad c \\neq 0, \\beta_i \\in \\mathbb{C}$$\n",
    "\n",
    "which means that there is at least one pair\n",
    "$\\left(\\lambda = \\beta_i \\in \\mathbb{C}, \\mathbf{\\nu} \\in \\mathcal{U}_{\\mathbb{C}}\\right)$\n",
    "such that $(\\mathbf{A} - \\lambda \\mathbf{I})\\mathbf{\\nu} = 0$.\n",
    "\n",
    "The result just presented in the form of a theorem indicates that every\n",
    "linear operator in $\\mathcal{U}$ has at least one pair of eigenvalue in\n",
    "$\\mathbb{C}$ and eigenvector in $\\mathcal{U}_{\\mathbb{C}}$. In fact,\n",
    "there can be more than one pair of eigenvalues and corresponding\n",
    "eigenvectors, and we can write Equation ?? in matrix form for $r$\n",
    "eigenvalues and eigenvectors as follows:\n",
    "$$\\mathbf{A\\nu} = \\mathbf{V \\Lambda}$$ where\n",
    "$$\\mathbf{V} = [\\mathbf{\\nu_1 \\nu_2 \\dots \\nu_r}]$$ is a matrix whose\n",
    "columns are the eigenvectors of $\\mathbf{A}$, and $$\\mathbf{\\Lambda} = \n",
    "\\begin{bmatrix}\n",
    "    \\lambda_1 & 0 & \\cdots & 0 \\\\\n",
    "    0 & \\lambda_2 & 0 & \\cdots \\\\\n",
    "    \\vdots & 0 & \\ddots & 0 \\\\\n",
    "    0 & \\cdots & 0 & \\lambda_r\n",
    "\\end{bmatrix}$$ is a diagonal matrix with the associated eigenvalues.\n",
    "\n",
    "From the definitions above, we can say that an eigenvector of a linear\n",
    "operator $\\mathbf{A}$ spans an invariant subspace under $\\mathbf{A}$\n",
    "with dimension equal to one. A single eigenvalue can sometimes be\n",
    "associated with multiple linearly independent eigenvectors. In this\n",
    "case, we say that this eigenvalue has geometrical multiplicity equal to\n",
    "the number of one-dimensional invariant subspaces spanned by its\n",
    "associated eigenvectors. We will see more of eigenvalue multiplicity\n",
    "towards the end of the present chapter.\n",
    "\n",
    "With the aid of a toy example, let us investigate the eigenvalues and\n",
    "eigenvectors of a simple linear operator.\n",
    "\n",
    "**Ex:** Let $\\mathbf{A}$ be a linear operator in $\\mathbb{R}^2$, induced\n",
    "by matrix $$\\mathbf{A} = \\begin{bmatrix}\n",
    "    1 & 1 \\\\\n",
    "    2 & 0\n",
    "\\end{bmatrix}$$ By inspection, We will see iterative methods that are\n",
    "capable of revealing eigenvalues and eigenvectors further in this\n",
    "Chapter and the book, but for the moment we may defer involved\n",
    "calculations and concentrate on the definitions. we can realize that\n",
    "vectors $\\mathbf{\\nu_1} = [1 \\ \\ 1]^{\\top}$ and\n",
    "$\\mathbf{\\nu_2} = [1 \\ \\ -2]^{\\top}$ both individually span subspaces of\n",
    "$\\mathbb{R}^2$ with dimension equal to one which are invariant under\n",
    "$\\mathbf{A}$. Therefore $\\nu_1$ and $\\nu_2$ are eigenvectors of $A$.\n",
    "Naturally, any vector $\\alpha \\nu_i$, where $\\alpha \\in \\mathbb{R}$, is\n",
    "also an eigenvector.\n",
    "\n",
    "$\\alpha \\in \\mathbb{R}$ and $i = 1, 2$, is also an eigenvector of\n",
    "$\\mathbf{A}$, because scaling does not change direction. For instance,\n",
    "we call this uniform scaling operation a homothety, or homogeneous\n",
    "dilation, with homothetic center at the origin. One particular homothety\n",
    "that comes handy is the one which renders the eigenvector with unitary\n",
    "Euclidean norm:\n",
    "$\\mathbf{\\bar{\\nu}_j} = \\mathbf{\\nu_j} / \\|\\mathbf{\\nu_j}\\|_2$. The\n",
    "scalars which settle the equation $\\mathbf{A\\nu} = \\lambda \\mathbf{\\nu}$\n",
    "are the associated eigenvalues: $\\lambda_1 = 2$ and $\\lambda_2 = -1$,\n",
    "respectively. We may construct matrices $\\mathbf{V}$ and\n",
    "$\\mathbf{\\Lambda}$ as $$\\mathbf{V} = \\begin{bmatrix}\n",
    "1 & 1 \\\\\n",
    "1 & -2\n",
    "\\end{bmatrix}, \\quad \n",
    "\\mathbf{\\Lambda} = \\begin{bmatrix}\n",
    "2 & 0 \\\\\n",
    "0 & -1\n",
    "\\end{bmatrix}$$ such that $$\\mathbf{A V} = \\mathbf{V \\Lambda}$$\n",
    "\n",
    "We can also verify that similar matrices share the same set of\n",
    "eigenvalues, according to the theorem below.\n",
    "\n",
    "Let $\\mathbf{A}$ and $\\mathbf{B}$ be similar matrices, i.e., there\n",
    "exists an invertible linear transformation $\\mathbf{P}$ such that\n",
    "$\\mathbf{A} = \\mathbf{P^{-1}BP}$. If $\\lambda$ is an eigenvalue of\n",
    "$\\mathbf{A}$ associated with the eigenvector $\\mathbf{\\nu}$, then\n",
    "$\\lambda$ is also an eigenvalue of $\\mathbf{B}$, but associated with the\n",
    "eigenvector $\\mathbf{x} = \\mathbf{P\\nu}$.\n",
    "\n",
    "If $\\lambda$ is an eigenvalue of $\\mathbf{A}$, then\n",
    "$\\mathbf{A\\nu} = \\lambda \\mathbf{\\nu}$. Furthermore, if $\\mathbf{A}$ and\n",
    "$\\mathbf{B}$ are similar, then $\\mathbf{PA} = \\mathbf{BP}$. Therefore,\n",
    "$\\mathbf{PA\\nu} = \\mathbf{BP\\nu}$. Now let $x = P\\nu$,\n",
    "\n",
    "$$\\mathbf{BP\\nu = Bx = PA\\nu =} \\lambda \\mathbf{P \\nu} = \\lambda \\mathbf{x} \\implies \\mathbf{B}x = \\lambda \\mathbf{x}$$\n",
    "\n",
    "In the previous example, we were able to identify two pairs of\n",
    "eigenvalue and eigenvector. Indeed, the next theorem and corollary show\n",
    "that the number of eigenvalues, $r$, cannot exceed $n$, the dimension of\n",
    "$\\mathcal{U}$."
   ],
   "id": "f6214a90-550c-480a-8648-70330fec6423"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
